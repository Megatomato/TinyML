ST Edge AI Core v2.2.0-20266 2adc00962
Created date          : 2025-08-16 22:04:31
Parameters            : generate --target stm32f4 --name network -m /Users/wnedo/Desktop/Projects/TinyML/artifacts/tiny_mnist_best_quantized.onnx --compression none --verbosity 1 --no-inputs-allocation --no-outputs-allocation --workspace /var/folders/nv/w_7s3kv11v7gy879798zkddr0000gn/T/mxAI_workspace799582169755842915556563163096672 --output /Users/wnedo/.stm32cubemx/network_output

Exec/report summary (generate)
--------------------------------------------------------------------------------------------------------------------------
model file         :   /Users/wnedo/Desktop/Projects/TinyML/artifacts/tiny_mnist_best_quantized.onnx                      
type               :   onnx                                                                                               
c_name             :   network                                                                                            
compression        :   none                                                                                               
optimization       :   balanced                                                                                           
target/series      :   stm32f4                                                                                            
workspace dir      :   /var/folders/nv/w_7s3kv11v7gy879798zkddr0000gn/T/mxAI_workspace799582169755842915556563163096672   
output dir         :   /Users/wnedo/.stm32cubemx/network_output                                                           
model_fmt          :   ss/ua per channel                                                                                  
model_name         :   tiny_mnist_best_quantized                                                                          
model_hash         :   0x3a2f234b945524db9b7cf76b84b3f8c4                                                                 
params #           :   28,979 items (113.20 KiB)                                                                          
--------------------------------------------------------------------------------------------------------------------------
input 1/1          :   'input', uint8(1x28x28x1), 784 Bytes, QLinear(0.012728234,33,uint8), user                          
output 1/1         :   'logits_QuantizeLin..conversion', uint8(1x7), 7 Bytes, QLinear(0.184269145,142,uint8), user        
macc               :   271,563                                                                                            
weights (ro)       :   108,268 B (105.73 KiB) (1 segment) / -7,648(-6.6%) vs float model                                  
activations (rw)   :   6,808 B (6.65 KiB) (1 segment)                                                                     
ram (total)        :   7,599 B (7.42 KiB) = 6,808 + 784 + 7                                                               
--------------------------------------------------------------------------------------------------------------------------

Model name - tiny_mnist_best_quantized
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
m_id   layer (type,original)                                            oshape                param/size            macc                     connected to   | c_size              c_macc                c_type                         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
0      input (Input, )                                                  [b:1,h:28,w:28,c:1]                                                                 |                                           
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
5      fc1_bias_const (Placeholder, DequantizeLinear)                   [b:100]               100/400                                                       | -400(-100.0%)                             
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
6      fc1_weight_Dequant..tput_const (Placeholder, DequantizeLinear)   [b:100,c:256]         25,600/102,400                                                | -102,400(-100.0%)                         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
7      fc2_bias_const (Placeholder, DequantizeLinear)                   [b:7]                 7/28                                                          | -28(-100.0%)                              
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
8      fc2_weight_Dequant..tput_const (Placeholder, DequantizeLinear)   [b:7,c:100]           700/2,800                                                     | -2,800(-100.0%)                           
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
9      input_QuantizeLinear_Output (Conversion, QuantizeLinear)         [b:1,h:28,w:28,c:1]                        1,568                            input   |                     -1,568(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
10     input_DequantizeLinear_Output (Conversion, DequantizeLinear)     [b:1,h:28,w:28,c:1]                        1,568      input_QuantizeLinear_Output   |                     -1,568(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
11     _Relu_output_0 (Conv2D, Conv)                                    [b:1,h:24,w:24,c:6]   156/624             86,406    input_DequantizeLinear_Output   | -624(-100.0%)       -86,406(-100.0%)      
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
12     _Relu_output_0_Qua..ear_Output (Conversion, QuantizeLinear)      [b:1,h:24,w:24,c:6]                        6,912                   _Relu_output_0   |                     -6,912(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
13     _Relu_output_0_Deq..ear_Output (Conversion, DequantizeLinear)    [b:1,h:24,w:24,c:6]                        6,912   _Relu_output_0_Qua..ear_Output   |                     -6,912(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
14     _MaxPool_output_0 (Pool, MaxPool)                                [b:1,h:12,w:12,c:6]                        3,456   _Relu_output_0_Deq..ear_Output   | +174(+100.0%)       +86,406(+2500.2%)     Conv2D_[0]                     
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
15     _MaxPool_output_0_..ear_Output (Conversion, QuantizeLinear)      [b:1,h:12,w:12,c:6]                        1,728                _MaxPool_output_0   |                     -1,728(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
16     _MaxPool_output_0_..ear_Output (Conversion, DequantizeLinear)    [b:1,h:12,w:12,c:6]                        1,728   _MaxPool_output_0_..ear_Output   |                     -1,728(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
17     _Relu_1_output_0 (Conv2D, Conv)                                  [b:1,h:8,w:8,c:16]    2,416/9,664        153,616   _MaxPool_output_0_..ear_Output   | -9,664(-100.0%)     -153,616(-100.0%)     
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
18     _Relu_1_output_0_Q..ear_Output (Conversion, QuantizeLinear)      [b:1,h:8,w:8,c:16]                         2,048                 _Relu_1_output_0   |                     -2,048(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
19     _Relu_1_output_0_D..ear_Output (Conversion, DequantizeLinear)    [b:1,h:8,w:8,c:16]                         2,048   _Relu_1_output_0_Q..ear_Output   |                     -2,048(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
20     _MaxPool_1_output_0 (Pool, MaxPool)                              [b:1,h:4,w:4,c:16]                         1,024   _Relu_1_output_0_D..ear_Output   | +2,464(+100.0%)     +153,616(+15001.6%)   Conv2D_[1]                     
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
21     _MaxPool_1_output_..ear_Output (Conversion, QuantizeLinear)      [b:1,h:4,w:4,c:16]                           512              _MaxPool_1_output_0   |                     -512(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
22     _MaxPool_1_output_..ear_Output (Conversion, DequantizeLinear)    [b:1,h:4,w:4,c:16]                           512   _MaxPool_1_output_..ear_Output   |                     -512(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
23     _Flatten_output_0 (Reshape, Flatten)                             [b:1,c:256]                                        _MaxPool_1_output_..ear_Output   |                     +640(+100.0%)         Transpose_/Conversion_[2, 3]   
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
24     _Flatten_output_0_..ear_Output (Conversion, QuantizeLinear)      [b:1,c:256]                                  512                _Flatten_output_0   |                     -512(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
25     _Flatten_output_0_..ear_Output (Conversion, DequantizeLinear)    [b:1,c:256]                                  512   _Flatten_output_0_..ear_Output   |                     -512(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
26     _Relu_2_output_0 (Gemm, Gemm)                                    [b:1,c:100]                               25,700   _Flatten_output_0_..ear_Output   | +102,800(+100.0%)                         Dense_[4]                      
                                                                                                                           fc1_weight_Dequant..tput_const   | 
                                                                                                                                           fc1_bias_const   | 
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
27     _Relu_2_output_0_Q..ear_Output (Conversion, QuantizeLinear)      [b:1,c:100]                                  200                 _Relu_2_output_0   |                     -200(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
28     _Relu_2_output_0_D..ear_Output (Conversion, DequantizeLinear)    [b:1,c:100]                                  200   _Relu_2_output_0_Q..ear_Output   |                     -200(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
29     logits_QuantizeLinear_Input (Gemm, Gemm)                         [b:1,c:7]                                    707   _Relu_2_output_0_D..ear_Output   | +2,828(+100.0%)     +14(+2.0%)            Dense_/Conversion_[o][5, 6]    
                                                                                                                           fc2_weight_Dequant..tput_const   | 
                                                                                                                                           fc2_bias_const   | 
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
30     logits_QuantizeLinear_Output (Conversion, QuantizeLinear)        [b:1,c:7]                                     14      logits_QuantizeLinear_Input   |                     -14(-100.0%)          
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
31     logits (Conversion, DequantizeLinear)                            [b:1,c:7]                                     14     logits_QuantizeLinear_Output   |                     -14(-100.0%)          
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
model/c-model: macc=297,897/271,563 -26,334(-8.8%) weights=115,916/108,268 -7,648(-6.6%) activations=--/6,808 io=--/791



Generated C-graph summary
------------------------------------------------------------------------------------------------------------------------
model name            : tiny_mnist_best_quantized
c-name                : network
c-node #              : 7
c-array #             : 20
activations size      : 6808 (1 segment)
weights size          : 108268 (1 segment)
macc                  : 271563
inputs                : ['input_output']
outputs               : ['logits_QuantizeLinear_Input_0_conversion_output']

C-Arrays (20)
------ -------------------------------------------------------------------- -------------- ------------------------- ------------- --------- 
c_id   name (*_array)                                                       item/size      domain/mem-pool           c-type        comment   
------ -------------------------------------------------------------------- -------------- ------------------------- ------------- --------- 
0      _Flatten_output_0_to_chlast_0_0__Relu_2_output_0_conversion_output   256/1024       activations/**default**   float                   
1      _Flatten_output_0_to_chlast_output                                   256/256        activations/**default**   u8                      
2      _Relu_1_output_0_bias                                                16/64          weights/weights           const s32               
3      _Relu_1_output_0_output                                              256/256        activations/**default**   u8                      
4      _Relu_1_output_0_scratch0                                            5624/5624      activations/**default**   s8                      
5      _Relu_1_output_0_scratch1                                            256/256        activations/**default**   u8                      
6      _Relu_1_output_0_weights                                             2400/2400      weights/weights           const s8                
7      _Relu_2_output_0_bias                                                100/400        weights/weights           const float             
8      _Relu_2_output_0_output                                              100/400        activations/**default**   float                   
9      _Relu_2_output_0_weights                                             25600/102400   weights/weights           const float             
10     _Relu_output_0_bias                                                  6/24           weights/weights           const s32               
11     _Relu_output_0_output                                                864/864        activations/**default**   u8                      
12     _Relu_output_0_scratch0                                              484/484        activations/**default**   s8                      
13     _Relu_output_0_scratch1                                              288/288        activations/**default**   u8                      
14     _Relu_output_0_weights                                               150/150        weights/weights           const s8                
15     input_output                                                         784/784        user/                     u8            /input    
16     logits_QuantizeLinear_Input_0_conversion_output                      7/7            user/                     u8            /output   
17     logits_QuantizeLinear_Input_bias                                     7/28           weights/weights           const float             
18     logits_QuantizeLinear_Input_output                                   7/28           activations/**default**   float                   
19     logits_QuantizeLinear_Input_weights                                  700/2800       weights/weights           const float             
------ -------------------------------------------------------------------- -------------- ------------------------- ------------- --------- 

C-Layers (7)
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
c_id   name (*_layer)                                                id   layer_type    macc     rom      tensors                                                                 shape (array id)        
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
0      _Relu_output_0                                                14   Conv2D        89862    174      I: input_output                                                         uint8(1x28x28x1) (15)   
                                                                                                          S: _Relu_output_0_scratch0                                                                      
                                                                                                          S: _Relu_output_0_scratch1                                                                      
                                                                                                          W: _Relu_output_0_weights                                               int8(6x5x5x1) (14)      
                                                                                                          W: _Relu_output_0_bias                                                  int32(6) (10)           
                                                                                                          O: _Relu_output_0_output                                                uint8(1x12x12x6) (11)   
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
1      _Relu_1_output_0                                              20   Conv2D        154640   2464     I: _Relu_output_0_output                                                uint8(1x12x12x6) (11)   
                                                                                                          S: _Relu_1_output_0_scratch0                                                                    
                                                                                                          S: _Relu_1_output_0_scratch1                                                                    
                                                                                                          W: _Relu_1_output_0_weights                                             int8(16x5x5x6) (6)      
                                                                                                          W: _Relu_1_output_0_bias                                                int32(16) (2)           
                                                                                                          O: _Relu_1_output_0_output                                              uint8(1x4x4x16) (3)     
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
2      _Flatten_output_0_to_chlast                                   23   Transpose     128      0        I: _Relu_1_output_0_output                                              uint8(1x4x4x16) (3)     
                                                                                                          O: _Flatten_output_0_to_chlast_output                                   uint8(1x16x4x4) (1)     
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
3      _Flatten_output_0_to_chlast_0_0__Relu_2_output_0_conversion   23   Conversion    512      0        I: _Flatten_output_0_to_chlast_output                                   uint8(1x16x4x4) (1)     
                                                                                                          O: _Flatten_output_0_to_chlast_0_0__Relu_2_output_0_conversion_output   f32(1x16x4x4) (0)       
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
4      _Relu_2_output_0                                              26   Dense         25700    102800   I: _Flatten_output_0_to_chlast_0_0__Relu_2_output_0_conversion_output   f32(1x16x4x4) (0)       
                                                                                                          W: _Relu_2_output_0_weights                                             f32(100x256) (9)        
                                                                                                          W: _Relu_2_output_0_bias                                                f32(100) (7)            
                                                                                                          O: _Relu_2_output_0_output                                              f32(1x100) (8)          
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
5      logits_QuantizeLinear_Input                                   29   Dense         707      2828     I: _Relu_2_output_0_output                                              f32(1x100) (8)          
                                                                                                          W: logits_QuantizeLinear_Input_weights                                  f32(7x100) (19)         
                                                                                                          W: logits_QuantizeLinear_Input_bias                                     f32(7) (17)             
                                                                                                          O: logits_QuantizeLinear_Input_output                                   f32(1x7) (18)           
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
6      logits_QuantizeLinear_Input_0_conversion                      29   Conversion    14       0        I: logits_QuantizeLinear_Input_output                                   f32(1x7) (18)           
                                                                                                          O: logits_QuantizeLinear_Input_0_conversion_output                      uint8(1x7) (16)         
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 



Number of operations per c-layer
------- ------ --------------------------------------------- --------- -------------- 
c_id    m_id   name (type)                                         #op           type 
------- ------ --------------------------------------------- --------- -------------- 
0       14     _Relu_output_0 (Conv2D)                          89,862     smul_u8_s8 
1       20     _Relu_1_output_0 (Conv2D)                       154,640     smul_u8_s8 
2       23     _Flatten_output_0_to_chlast (Transpose)             128     smul_u8_u8 
3       23     _Flatten_output_0_..conversion (Conversion)         512    smul_u8_f32 
4       26     _Relu_2_output_0 (Dense)                         25,700   smul_f32_f32 
5       29     logits_QuantizeLinear_Input (Dense)                 707   smul_f32_f32 
6       29     logits_QuantizeLin..conversion (Conversion)          14    smul_f32_u8 
------- ------ --------------------------------------------- --------- -------------- 
total                                                          271,563 

Number of operation types
---------------- --------- ----------- 
operation type           #           % 
---------------- --------- ----------- 
smul_u8_s8         244,502       90.0% 
smul_u8_u8             128        0.0% 
smul_u8_f32            512        0.2% 
smul_f32_f32        26,407        9.7% 
smul_f32_u8             14        0.0% 

Complexity report (model)
------ ----------------------------- ------------------------- ------------------------- -------- 
m_id   name                          c_macc                    c_rom                     c_id     
------ ----------------------------- ------------------------- ------------------------- -------- 
14     _MaxPool_output_0             |||||||||         33.1%   |                  0.2%   [0]      
20     _MaxPool_1_output_0           ||||||||||||||||  56.9%   |                  2.3%   [1]      
23     _Flatten_output_0             |                  0.2%   |                  0.0%   [2, 3]   
26     _Relu_2_output_0              |||                9.5%   ||||||||||||||||  94.9%   [4]      
29     logits_QuantizeLinear_Input   |                  0.3%   |                  2.6%   [5, 6]   
------ ----------------------------- ------------------------- ------------------------- -------- 
macc=271,563 weights=108,268 act=6,808 ram_io=791
 
 Requested memory size by section - "stm32f4" target
 ------------------------------ -------- --------- ------- ------- 
 module                             text    rodata    data     bss 
 ------------------------------ -------- --------- ------- ------- 
 NetworkRuntime1020_CM4_GCC.a     22,244         0       0       0 
 network.o                           644       345   2,620     208 
 network_data.o                       48        16      88       0 
 lib (toolchain)*                  1,928        24       0       0 
 ------------------------------ -------- --------- ------- ------- 
 RT total**                       24,864       385   2,708     208 
 ------------------------------ -------- --------- ------- ------- 
 weights                               0   108,272       0       0 
 activations                           0         0       0   6,808 
 io                                    0         0       0     791 
 ------------------------------ -------- --------- ------- ------- 
 TOTAL                            24,864   108,657   2,708   7,807 
 ------------------------------ -------- --------- ------- ------- 
 *  toolchain objects (libm/libgcc*)
 ** RT AI runtime objects (kernels+infrastructure)
  
  Summary - "stm32f4" target
  ---------------------------------------------------
               FLASH (ro)      %*   RAM (rw)       % 
  ---------------------------------------------------
  RT total         27,957   20.5%      2,916   27.7% 
  ---------------------------------------------------
  TOTAL           136,229             10,515         
  ---------------------------------------------------
  *  rt/total


Generated files (7)
---------------------------------------------------------------- 
/Users/wnedo/.stm32cubemx/network_output/network_data_params.h   
/Users/wnedo/.stm32cubemx/network_output/network_data_params.c   
/Users/wnedo/.stm32cubemx/network_output/network_data.h          
/Users/wnedo/.stm32cubemx/network_output/network_data.c          
/Users/wnedo/.stm32cubemx/network_output/network_config.h        
/Users/wnedo/.stm32cubemx/network_output/network.h               
/Users/wnedo/.stm32cubemx/network_output/network.c               
