ST Edge AI Core v2.2.0-20266 2adc00962
Created date          : 2025-08-16 18:50:16
Parameters            : validate --target stm32f4 --name network -m /Users/wnedo/Desktop/Projects/TinyML/artifacts/tiny_mnist_best_quantized.onnx --compression none --verbosity 1 --no-inputs-allocation --no-outputs-allocation --workspace /var/folders/nv/w_7s3kv11v7gy879798zkddr0000gn/T/mxAI_workspace7276395547887512832800654174414168 --output /Users/wnedo/.stm32cubemx/network_output --mode target --desc serial:/dev/tty.usbmodem11103:115200

Exec/report summary (validate)
---------------------------------------------------------------------------------------------------------------------------
model file         :   /Users/wnedo/Desktop/Projects/TinyML/artifacts/tiny_mnist_best_quantized.onnx                       
type               :   onnx                                                                                                
c_name             :   network                                                                                             
compression        :   none                                                                                                
optimization       :   balanced                                                                                            
target/series      :   stm32f4                                                                                             
workspace dir      :   /var/folders/nv/w_7s3kv11v7gy879798zkddr0000gn/T/mxAI_workspace7276395547887512832800654174414168   
output dir         :   /Users/wnedo/.stm32cubemx/network_output                                                            
model_fmt          :   ss/ua per channel                                                                                   
model_name         :   tiny_mnist_best_quantized                                                                           
model_hash         :   0x3a2f234b945524db9b7cf76b84b3f8c4                                                                  
params #           :   28,979 items (113.20 KiB)                                                                           
---------------------------------------------------------------------------------------------------------------------------
input 1/1          :   'input', uint8(1x28x28x1), 784 Bytes, QLinear(0.012728234,33,uint8), user                           
output 1/1         :   'logits_QuantizeLin..conversion', uint8(1x7), 7 Bytes, QLinear(0.184269145,142,uint8), user         
macc               :   271,563                                                                                             
weights (ro)       :   108,268 B (105.73 KiB) (1 segment) / -7,648(-6.6%) vs float model                                   
activations (rw)   :   6,808 B (6.65 KiB) (1 segment)                                                                      
ram (total)        :   7,599 B (7.42 KiB) = 6,808 + 784 + 7                                                                
---------------------------------------------------------------------------------------------------------------------------

Model name - tiny_mnist_best_quantized
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
m_id   layer (type,original)                                            oshape                param/size            macc                     connected to   | c_size              c_macc                c_type                         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
0      input (Input, )                                                  [b:1,h:28,w:28,c:1]                                                                 |                                           
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
5      fc1_bias_const (Placeholder, DequantizeLinear)                   [b:100]               100/400                                                       | -400(-100.0%)                             
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
6      fc1_weight_Dequant..tput_const (Placeholder, DequantizeLinear)   [b:100,c:256]         25,600/102,400                                                | -102,400(-100.0%)                         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
7      fc2_bias_const (Placeholder, DequantizeLinear)                   [b:7]                 7/28                                                          | -28(-100.0%)                              
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
8      fc2_weight_Dequant..tput_const (Placeholder, DequantizeLinear)   [b:7,c:100]           700/2,800                                                     | -2,800(-100.0%)                           
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
9      input_QuantizeLinear_Output (Conversion, QuantizeLinear)         [b:1,h:28,w:28,c:1]                        1,568                            input   |                     -1,568(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
10     input_DequantizeLinear_Output (Conversion, DequantizeLinear)     [b:1,h:28,w:28,c:1]                        1,568      input_QuantizeLinear_Output   |                     -1,568(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
11     _Relu_output_0 (Conv2D, Conv)                                    [b:1,h:24,w:24,c:6]   156/624             86,406    input_DequantizeLinear_Output   | -624(-100.0%)       -86,406(-100.0%)      
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
12     _Relu_output_0_Qua..ear_Output (Conversion, QuantizeLinear)      [b:1,h:24,w:24,c:6]                        6,912                   _Relu_output_0   |                     -6,912(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
13     _Relu_output_0_Deq..ear_Output (Conversion, DequantizeLinear)    [b:1,h:24,w:24,c:6]                        6,912   _Relu_output_0_Qua..ear_Output   |                     -6,912(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
14     _MaxPool_output_0 (Pool, MaxPool)                                [b:1,h:12,w:12,c:6]                        3,456   _Relu_output_0_Deq..ear_Output   | +174(+100.0%)       +86,406(+2500.2%)     Conv2D_[0]                     
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
15     _MaxPool_output_0_..ear_Output (Conversion, QuantizeLinear)      [b:1,h:12,w:12,c:6]                        1,728                _MaxPool_output_0   |                     -1,728(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
16     _MaxPool_output_0_..ear_Output (Conversion, DequantizeLinear)    [b:1,h:12,w:12,c:6]                        1,728   _MaxPool_output_0_..ear_Output   |                     -1,728(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
17     _Relu_1_output_0 (Conv2D, Conv)                                  [b:1,h:8,w:8,c:16]    2,416/9,664        153,616   _MaxPool_output_0_..ear_Output   | -9,664(-100.0%)     -153,616(-100.0%)     
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
18     _Relu_1_output_0_Q..ear_Output (Conversion, QuantizeLinear)      [b:1,h:8,w:8,c:16]                         2,048                 _Relu_1_output_0   |                     -2,048(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
19     _Relu_1_output_0_D..ear_Output (Conversion, DequantizeLinear)    [b:1,h:8,w:8,c:16]                         2,048   _Relu_1_output_0_Q..ear_Output   |                     -2,048(-100.0%)       
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
20     _MaxPool_1_output_0 (Pool, MaxPool)                              [b:1,h:4,w:4,c:16]                         1,024   _Relu_1_output_0_D..ear_Output   | +2,464(+100.0%)     +153,616(+15001.6%)   Conv2D_[1]                     
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
21     _MaxPool_1_output_..ear_Output (Conversion, QuantizeLinear)      [b:1,h:4,w:4,c:16]                           512              _MaxPool_1_output_0   |                     -512(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
22     _MaxPool_1_output_..ear_Output (Conversion, DequantizeLinear)    [b:1,h:4,w:4,c:16]                           512   _MaxPool_1_output_..ear_Output   |                     -512(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
23     _Flatten_output_0 (Reshape, Flatten)                             [b:1,c:256]                                        _MaxPool_1_output_..ear_Output   |                     +640(+100.0%)         Transpose_/Conversion_[2, 3]   
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
24     _Flatten_output_0_..ear_Output (Conversion, QuantizeLinear)      [b:1,c:256]                                  512                _Flatten_output_0   |                     -512(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
25     _Flatten_output_0_..ear_Output (Conversion, DequantizeLinear)    [b:1,c:256]                                  512   _Flatten_output_0_..ear_Output   |                     -512(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
26     _Relu_2_output_0 (Gemm, Gemm)                                    [b:1,c:100]                               25,700   _Flatten_output_0_..ear_Output   | +102,800(+100.0%)                         Dense_[4]                      
                                                                                                                           fc1_weight_Dequant..tput_const   | 
                                                                                                                                           fc1_bias_const   | 
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
27     _Relu_2_output_0_Q..ear_Output (Conversion, QuantizeLinear)      [b:1,c:100]                                  200                 _Relu_2_output_0   |                     -200(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
28     _Relu_2_output_0_D..ear_Output (Conversion, DequantizeLinear)    [b:1,c:100]                                  200   _Relu_2_output_0_Q..ear_Output   |                     -200(-100.0%)         
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
29     logits_QuantizeLinear_Input (Gemm, Gemm)                         [b:1,c:7]                                    707   _Relu_2_output_0_D..ear_Output   | +2,828(+100.0%)     +14(+2.0%)            Dense_/Conversion_[o][5, 6]    
                                                                                                                           fc2_weight_Dequant..tput_const   | 
                                                                                                                                           fc2_bias_const   | 
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
30     logits_QuantizeLinear_Output (Conversion, QuantizeLinear)        [b:1,c:7]                                     14      logits_QuantizeLinear_Input   |                     -14(-100.0%)          
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
31     logits (Conversion, DequantizeLinear)                            [b:1,c:7]                                     14     logits_QuantizeLinear_Output   |                     -14(-100.0%)          
------ ---------------------------------------------------------------- --------------------- ---------------- --------- -------------------------------- --- ------------------- --------------------- ------------------------------ 
model/c-model: macc=297,897/271,563 -26,334(-8.8%) weights=115,916/108,268 -7,648(-6.6%) activations=--/6,808 io=--/791



Generated C-graph summary
------------------------------------------------------------------------------------------------------------------------
model name            : tiny_mnist_best_quantized
c-name                : network
c-node #              : 7
c-array #             : 20
activations size      : 6808 (1 segment)
weights size          : 108268 (1 segment)
macc                  : 271563
inputs                : ['input_output']
outputs               : ['logits_QuantizeLinear_Input_0_conversion_output']

C-Arrays (20)
------ -------------------------------------------------------------------- -------------- ------------------------- ------------- --------- 
c_id   name (*_array)                                                       item/size      domain/mem-pool           c-type        comment   
------ -------------------------------------------------------------------- -------------- ------------------------- ------------- --------- 
0      _Flatten_output_0_to_chlast_0_0__Relu_2_output_0_conversion_output   256/1024       activations/**default**   float                   
1      _Flatten_output_0_to_chlast_output                                   256/256        activations/**default**   u8                      
2      _Relu_1_output_0_bias                                                16/64          weights/weights           const s32               
3      _Relu_1_output_0_output                                              256/256        activations/**default**   u8                      
4      _Relu_1_output_0_scratch0                                            5624/5624      activations/**default**   s8                      
5      _Relu_1_output_0_scratch1                                            256/256        activations/**default**   u8                      
6      _Relu_1_output_0_weights                                             2400/2400      weights/weights           const s8                
7      _Relu_2_output_0_bias                                                100/400        weights/weights           const float             
8      _Relu_2_output_0_output                                              100/400        activations/**default**   float                   
9      _Relu_2_output_0_weights                                             25600/102400   weights/weights           const float             
10     _Relu_output_0_bias                                                  6/24           weights/weights           const s32               
11     _Relu_output_0_output                                                864/864        activations/**default**   u8                      
12     _Relu_output_0_scratch0                                              484/484        activations/**default**   s8                      
13     _Relu_output_0_scratch1                                              288/288        activations/**default**   u8                      
14     _Relu_output_0_weights                                               150/150        weights/weights           const s8                
15     input_output                                                         784/784        user/                     u8            /input    
16     logits_QuantizeLinear_Input_0_conversion_output                      7/7            user/                     u8            /output   
17     logits_QuantizeLinear_Input_bias                                     7/28           weights/weights           const float             
18     logits_QuantizeLinear_Input_output                                   7/28           activations/**default**   float                   
19     logits_QuantizeLinear_Input_weights                                  700/2800       weights/weights           const float             
------ -------------------------------------------------------------------- -------------- ------------------------- ------------- --------- 

C-Layers (7)
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
c_id   name (*_layer)                                                id   layer_type    macc     rom      tensors                                                                 shape (array id)        
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
0      _Relu_output_0                                                14   Conv2D        89862    174      I: input_output                                                         uint8(1x28x28x1) (15)   
                                                                                                          S: _Relu_output_0_scratch0                                                                      
                                                                                                          S: _Relu_output_0_scratch1                                                                      
                                                                                                          W: _Relu_output_0_weights                                               int8(6x5x5x1) (14)      
                                                                                                          W: _Relu_output_0_bias                                                  int32(6) (10)           
                                                                                                          O: _Relu_output_0_output                                                uint8(1x12x12x6) (11)   
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
1      _Relu_1_output_0                                              20   Conv2D        154640   2464     I: _Relu_output_0_output                                                uint8(1x12x12x6) (11)   
                                                                                                          S: _Relu_1_output_0_scratch0                                                                    
                                                                                                          S: _Relu_1_output_0_scratch1                                                                    
                                                                                                          W: _Relu_1_output_0_weights                                             int8(16x5x5x6) (6)      
                                                                                                          W: _Relu_1_output_0_bias                                                int32(16) (2)           
                                                                                                          O: _Relu_1_output_0_output                                              uint8(1x4x4x16) (3)     
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
2      _Flatten_output_0_to_chlast                                   23   Transpose     128      0        I: _Relu_1_output_0_output                                              uint8(1x4x4x16) (3)     
                                                                                                          O: _Flatten_output_0_to_chlast_output                                   uint8(1x16x4x4) (1)     
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
3      _Flatten_output_0_to_chlast_0_0__Relu_2_output_0_conversion   23   Conversion    512      0        I: _Flatten_output_0_to_chlast_output                                   uint8(1x16x4x4) (1)     
                                                                                                          O: _Flatten_output_0_to_chlast_0_0__Relu_2_output_0_conversion_output   f32(1x16x4x4) (0)       
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
4      _Relu_2_output_0                                              26   Dense         25700    102800   I: _Flatten_output_0_to_chlast_0_0__Relu_2_output_0_conversion_output   f32(1x16x4x4) (0)       
                                                                                                          W: _Relu_2_output_0_weights                                             f32(100x256) (9)        
                                                                                                          W: _Relu_2_output_0_bias                                                f32(100) (7)            
                                                                                                          O: _Relu_2_output_0_output                                              f32(1x100) (8)          
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
5      logits_QuantizeLinear_Input                                   29   Dense         707      2828     I: _Relu_2_output_0_output                                              f32(1x100) (8)          
                                                                                                          W: logits_QuantizeLinear_Input_weights                                  f32(7x100) (19)         
                                                                                                          W: logits_QuantizeLinear_Input_bias                                     f32(7) (17)             
                                                                                                          O: logits_QuantizeLinear_Input_output                                   f32(1x7) (18)           
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
6      logits_QuantizeLinear_Input_0_conversion                      29   Conversion    14       0        I: logits_QuantizeLinear_Input_output                                   f32(1x7) (18)           
                                                                                                          O: logits_QuantizeLinear_Input_0_conversion_output                      uint8(1x7) (16)         
------ ------------------------------------------------------------- ---- ------------- -------- -------- ----------------------------------------------------------------------- ----------------------- 
 
Setting validation data...
 generating random data, size=10, seed=42, range=(0, 1)
   I[1]: (10, 28, 28, 1)/float32, min/max=[-0.419994, 2.824752], mean/std=[1.187755, 0.937795]
    c/I[1] conversion [Q(0.01272823,33)]-> (10, 28, 28, 1)/uint8, min/max=[0, 255], mean/std=[126.319260, 73.678841]
    m/I[1] no modification.
 no output/reference samples are provided
 
Running the ST.AI c-model (AI RUNNER)...(name=network, mode=TARGET)

 Proto-buffer driver v2.0 (msg v3.1) (Serial driver v1.0 - /dev/tty.usbmodem11103:115200) ['network']
  
  Summary 'network' - ['network']
  -------------------------------------------------------------------------------------------------------------------
  I[1/1] 'input_1'    :   uint8[1,28,28,1], 784 Bytes, QLinear(0.012728234,33,uint8), user                           
  O[1/1] 'output_1'   :   uint8[1,1,1,7], 7 Bytes, QLinear(0.184269145,142,uint8), user                              
  n_nodes             :   7                                                                                          
  activations         :   6808                                                                                       
  weights             :   108268                                                                                     
  macc                :   271563                                                                                     
  hash                :   0x3a2f234b945524db9b7cf76b84b3f8c4                                                         
  compile_datetime    :   Aug 16 2025 18:49:57                                                                       
  -------------------------------------------------------------------------------------------------------------------
  protocol            :   Proto-buffer driver v2.0 (msg v3.1) (Serial driver v1.0 - /dev/tty.usbmodem11103:115200)   
  tools               :   ST.AI (legacy api) v2.2.0                                                                  
  runtime lib         :   v10.1.0-ae536891 compiled with GCC 12.3.1 (GCC)                                            
  capabilities        :   IO_ONLY, PER_LAYER, PER_LAYER_WITH_DATA                                                    
  device.desc         :   stm32 family - 0x421 - STM32F446 @180/180MHz                                               
  device.attrs        :   fpu,art_lat=5,art_prefetch,art_icache,art_dcache                                           
  -------------------------------------------------------------------------------------------------------------------
  
  ST.AI Profiling results v2.0 - "network"
  ---------------------------------------------------------------
  nb sample(s)      :   10                                       
  duration          :   9.273 ms by sample (9.272/9.273/0.000)   
  macc              :   271563                                   
  cycles/MACC       :   6.15                                     
  CPU cycles        :   [1,669,110]                              
  used stack/heap   :   not monitored/0 bytes                    
  ---------------------------------------------------------------
   
   Inference time per node
   ---------------------------------------------------------------------------------------------
   c_id    m_id   type                   dur (ms)       %    cumul  CPU cycles      name        
   ---------------------------------------------------------------------------------------------
   0       14     Conv2dPool (0x109)        4.961   53.5%    53.5%  [   893,053 ]   ai_node_0   
   1       20     Conv2dPool (0x109)        2.988   32.2%    85.7%  [   537,807 ]   ai_node_1   
   2       23     Transpose (0x10a)         0.090    1.0%    86.7%  [    16,261 ]   ai_node_2   
   3       23     NL (0x107)                0.019    0.2%    86.9%  [     3,388 ]   ai_node_3   
   4       26     Dense (0x104)             1.176   12.7%    99.6%  [   211,694 ]   ai_node_4   
   5       29     Dense (0x104)             0.036    0.4%   100.0%  [     6,458 ]   ai_node_5   
   6       29     NL (0x107)                0.002    0.0%   100.0%  [       449 ]   ai_node_6   
   ---------------------------------------------------------------------------------------------
   total                                    9.273                   [ 1,669,110 ]               
   ---------------------------------------------------------------------------------------------
   
   Statistic per tensor
   -----------------------------------------------------------------------------
   tensor   #    type[shape]:size      min   max      mean      std  name       
   -----------------------------------------------------------------------------
   I.0      10   u8[1,28,28,1]:784       0   255   126.319   73.679  input_1    
   O.0      10   u8[1,1,1,7]:7         120   175   150.329   12.087  output_1   
   -----------------------------------------------------------------------------
 
Saving validation data...
 output directory: /Users/wnedo/.stm32cubemx/network_output
 creating /Users/wnedo/.stm32cubemx/network_output/network_val_io.npz
 m_outputs_1: (10, 7)/float64, min/max=[-2.395499, 1.842691], mean/std=[-0.300095, 0.932946], logits_QuantizeLinear_Input_0_conversion
 c_outputs_1: (10, 1, 1, 7)/uint8, min/max=[120, 175], mean/std=[150.328571, 12.087445], scale=0.184269145 zp=142, logits_QuantizeLinear_Input_0_conversion

 
Computing the metrics...

 Cross accuracy report #1 (reference vs C-model)
 ----------------------------------------------------------------------------------------------------
 notes: - data type is different: r/float64 instead p/uint8
        - p/uint8 data are dequantized with s=0.18426914513111115 zp=142
        - ACC metric is not computed ("--classifier" option can be used to force it)
        - the output of the reference model is used as ground truth/reference value
        - 10 samples (7 items per sample)

  acc=n.a. rmse=2.402272701 mae=2.050652742 l2r=0.888126552 mean=-1.834794 std=1.561823 nse=-5.535564 cos=0.472659 


Number of operations per c-layer
------- ------ --------------------------------------------- --------- -------------- 
c_id    m_id   name (type)                                         #op           type 
------- ------ --------------------------------------------- --------- -------------- 
0       14     _Relu_output_0 (Conv2D)                          89,862     smul_u8_s8 
1       20     _Relu_1_output_0 (Conv2D)                       154,640     smul_u8_s8 
2       23     _Flatten_output_0_to_chlast (Transpose)             128     smul_u8_u8 
3       23     _Flatten_output_0_..conversion (Conversion)         512    smul_u8_f32 
4       26     _Relu_2_output_0 (Dense)                         25,700   smul_f32_f32 
5       29     logits_QuantizeLinear_Input (Dense)                 707   smul_f32_f32 
6       29     logits_QuantizeLin..conversion (Conversion)          14    smul_f32_u8 
------- ------ --------------------------------------------- --------- -------------- 
total                                                          271,563 

Number of operation types
---------------- --------- ----------- 
operation type           #           % 
---------------- --------- ----------- 
smul_u8_s8         244,502       90.0% 
smul_u8_u8             128        0.0% 
smul_u8_f32            512        0.2% 
smul_f32_f32        26,407        9.7% 
smul_f32_u8             14        0.0% 

Complexity report (model)
------ ----------------------------- ------------------------- ------------------------- -------- -------- ---------------- 
m_id   name                          c_macc                    c_rom                     c_id     c_dur    l2r (X-CROSS)    
------ ----------------------------- ------------------------- ------------------------- -------- -------- ---------------- 
14     _MaxPool_output_0             |||||||||         33.1%   |                  0.2%   [0]       53.5%                    
20     _MaxPool_1_output_0           ||||||||||||||||  56.9%   |                  2.3%   [1]       32.2%                    
23     _Flatten_output_0             |                  0.2%   |                  0.0%   [2, 3]     1.2%                    
26     _Relu_2_output_0              |||                9.5%   ||||||||||||||||  94.9%   [4]       12.7%                    
29     logits_QuantizeLinear_Input   |                  0.3%   |                  2.6%   [5, 6]     0.4%   8.88126552e-01   
------ ----------------------------- ------------------------- ------------------------- -------- -------- ---------------- 
macc=271,563 weights=108,268 act=6,808 ram_io=791

Evaluation report (summary)
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Output       acc    rmse          mae           l2r           mean        std        nse         cos        tensor                                                         
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------
X-cross #1   n.a.   2.402272701   2.050652742   0.888126552   -1.834794   1.561823   -5.535564   0.472659   'logits_QuantizeLin..conversion', 10 x uint8(1x7), m_id=[29]   
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

 acc  : Accuracy (class, axis=-1)
 rmse : Root Mean Squared Error
 mae  : Mean Absolute Error
 l2r  : L2 relative error
 mean : Mean error
 std  : Standard deviation error
 nse  : Nash-Sutcliffe efficiency criteria, bigger is better, best=1, range=(-inf, 1]
 cos  : COsine Similarity, bigger is better, best=1, range=(0, 1]
